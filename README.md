# AdvertiseX Data Engineering Project

## Overview

This project is designed to address data engineering challenges at AdvertiseX, a digital advertising technology company. The project handles the ingestion, processing, and storage of vast amounts of data generated by ad impressions, clicks, conversions, and bid requests. It uses Apache Kafka for streaming data ingestion, Apache Spark for processing, and AWS S3 and Redshift for storage and analytics.

## Directory Structure

advertizex/
│
├── data_ingestion/
│   ├── kafka_producer.py
│   ├── kafka_connect_csv.py
│   └── kafka_avro_producer.py
│
├── data_processing/
│   ├── spark_batch_processing.py
│   └── spark_streaming_processing.py
│
├── data_storage/
│   ├── s3_storage.py
│   └── redshift_storage.py
│
├── error_handling_monitoring/
│   ├── data_validation.py
│   └── airflow_dag.py
│
├── requirements.txt
└── README.md

## Setup Instructions

### Prerequisites

- Docker
- AWS account with access to S3 and Redshift
- Kafka setup (local or cloud)

### Build Docker Image

1. Clone the repository:

    ```sh
    git clone <repository-url>
    cd <repository-directory>
    ```

2. Build the Docker image:

    ```sh
    docker build -t advertise-x-app .
    ```

### Run Docker Container

To run a specific script, you can override the default command in the Dockerfile. For example, to run the `spark_streaming_processing.py` script:

```sh
docker run -e AWS_ACCESS_KEY_ID=your_access_key -e AWS_SECRET_ACCESS_KEY=your_secret_key -e AWS_REGION=your_region advertise-x-app python data_processing/spark_streaming_processing.py

